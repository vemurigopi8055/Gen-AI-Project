{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0eef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e81b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class states(dict):\n",
    "    paragraph: str\n",
    "    structured_data:dict | None\n",
    "    is_chat: bool\n",
    "    generated_code : str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec54d7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002902EFBD940>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002902EFBE510>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "global model\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=\"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\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43e360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_values(state: states):\n",
    "    prompt = f\"\"\"\n",
    "            Extract chartable data from this paragraph.\n",
    "            Respond ONLY in JSON format like this:\n",
    "            {{\n",
    "            \"x_axis\": [...],\n",
    "            \"y_axis\": [...],\n",
    "            \"chart_type\": \"bar|line|pie\"\n",
    "            }}\n",
    "            If no chart is possible, respond with: \"NO_CHART\"\n",
    "\n",
    "\n",
    "            Paragraph: {state['paragraph']}\n",
    "        \"\"\"\n",
    "    res = model.predict(prompt)\n",
    "    if \"NO_CHART\" in res:\n",
    "        state[\"structured_data\"] = None\n",
    "    else:\n",
    "        import json\n",
    "        try:\n",
    "            state[\"structured_data\"] = json.loads(res)\n",
    "        except Exception:\n",
    "            state[\"structured_data\"] = None\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f40f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_possible(state: states):\n",
    "    if state[\"structured_data\"] is None:\n",
    "        state[\"is_chat\"] = False\n",
    "    else:\n",
    "        state[\"is_chat\"] = True\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddfa252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "def generate_the_plot(state: states):\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"You are a Python data visualization assistant. \n",
    "                I will provide:\n",
    "                - X values\n",
    "                - Y values\n",
    "                - A description of the chart type or style I want\n",
    "\n",
    "                Your task:\n",
    "                1. Generate valid Python code using matplotlib (and seaborn if needed) to plot the chart.\n",
    "                2. The code must:\n",
    "                - Import necessary libraries\n",
    "                - Plot the chart correctly\n",
    "                - Add axis labels and a title (if applicable)\n",
    "                - Call plt.show() at the end\n",
    "                3. Do not include explanations or comments, only return Python code.\n",
    "                \"\"\"),\n",
    "            (\"user\", \"{message}\")\n",
    "        ]\n",
    "    )\n",
    "    chain = template|model\n",
    "    res = chain.invoke({\"message\":state[\"structured_data\"]})\n",
    "    state[\"generated_code\"] = res.content\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be65e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def remove_invalid_lines(code):\n",
    "    valid_lines = []\n",
    "    for line in code.splitlines():\n",
    "        try:\n",
    "            ast.parse(line)\n",
    "            valid_lines.append(line)\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "    return \"\\n\".join(valid_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def run_the_code(filename):\n",
    "    result = subprocess.run(\n",
    "        [\"python\", f\"./generated_codes/{filename}\"],\n",
    "        capture_output=True\n",
    "    )\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b2ae805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250903_003341.py\n",
      "b'Figure(1000x600)\\r\\n'\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "# Example paragraph\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "import datetime\n",
    "\n",
    "paragraph = \"\"\"\n",
    "    Over the past five years, the adoption of renewable energy has steadily increased, with solar energy showing the fastest growth compared to wind and hydro power. Solar installations have grown at a higher rate year after year, while wind energy has maintained moderate but consistent expansion. Hydropower, on the other hand, has remained relatively stable with only slight improvements. A visualization comparing these three energy sources over time would clearly highlight solarâ€™s rapid rise against the steadier trends of wind and hydro.\n",
    "\"\"\"\n",
    "\n",
    "# Initial state\n",
    "state = states(paragraph=paragraph, structured_data=None, is_chat=False)\n",
    "\n",
    "graph = StateGraph(states)\n",
    "graph.add_node(\"extract\", get_the_values)\n",
    "graph.add_node(\"decide\", chart_possible)\n",
    "graph.add_node(\"chart\", generate_the_plot)\n",
    "\n",
    "graph.set_entry_point(\"extract\")\n",
    "graph.add_edge(\"extract\", \"decide\")\n",
    "graph.add_conditional_edges(\n",
    "    \"decide\",\n",
    "    lambda state: \"chart\" if state[\"is_chat\"] else END,\n",
    "    {\n",
    "        \"chart\": \"chart\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"chart\",END)\n",
    "\n",
    "flow = graph.compile()\n",
    "\n",
    "res = flow.invoke(state)\n",
    "output = remove_invalid_lines(res['generated_code'])\n",
    "\n",
    "if res['generated_code'] is not None:\n",
    "    filename = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".py\"\n",
    "    print(filename)\n",
    "    with open(f\"./generated_codes/{filename}\", \"w\") as f:\n",
    "        f.writelines(output)\n",
    "        f.close()\n",
    "\n",
    "run_the_code(filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
